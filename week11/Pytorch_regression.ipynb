{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Pytorch_regression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fleet-potter"
      },
      "source": [
        "# Predicting house prices with neural networks"
      ],
      "id": "fleet-potter"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sunset-blast"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "id": "sunset-blast",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "likely-interaction"
      },
      "source": [
        "## Data"
      ],
      "id": "likely-interaction"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruled-spider"
      },
      "source": [
        "### loading the data"
      ],
      "id": "ruled-spider"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "grave-snake",
        "outputId": "788f76be-15bb-4c88-e1b4-091ef6e7439e"
      },
      "source": [
        "raw_data = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/BigScaleAnalytics/master/week11/data/train.csv\")\n",
        "raw_data.head()"
      ],
      "id": "grave-snake",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>...</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
              "0   1          60       RL  ...        WD         Normal    208500\n",
              "1   2          20       RL  ...        WD         Normal    181500\n",
              "2   3          60       RL  ...        WD         Normal    223500\n",
              "3   4          70       RL  ...        WD        Abnorml    140000\n",
              "4   5          60       RL  ...        WD         Normal    250000\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adjacent-substance",
        "outputId": "7b416996-def1-465b-99ee-db565fc489c7"
      },
      "source": [
        "raw_data.shape"
      ],
      "id": "adjacent-substance",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 81)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "annual-officer"
      },
      "source": [
        "### Extracting the numeric columns"
      ],
      "id": "annual-officer"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "identified-wildlife",
        "outputId": "7c7272e6-8fce-4c24-c6ce-c13a4190386e"
      },
      "source": [
        "raw_data.dtypes"
      ],
      "id": "identified-wildlife",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                 int64\n",
              "MSSubClass         int64\n",
              "MSZoning          object\n",
              "LotFrontage      float64\n",
              "LotArea            int64\n",
              "                  ...   \n",
              "MoSold             int64\n",
              "YrSold             int64\n",
              "SaleType          object\n",
              "SaleCondition     object\n",
              "SalePrice          int64\n",
              "Length: 81, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rubber-corrections",
        "outputId": "62db49e5-d637-44a1-fcc9-c28c78d7a363"
      },
      "source": [
        "numeric_columns = list(raw_data.columns[(raw_data.dtypes==np.int64) |\n",
        "                 (raw_data.dtypes==np.float64)])\n",
        "print(numeric_columns, \"\\n\", len(numeric_columns))"
      ],
      "id": "rubber-corrections",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice'] \n",
            " 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "announced-incidence"
      },
      "source": [
        "Set `SalesPrice` as the last index, since it is the value we want to predict."
      ],
      "id": "announced-incidence"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "intermediate-cable"
      },
      "source": [
        "numeric_columns.remove('SalePrice')\n",
        "numeric_columns.append('SalePrice')"
      ],
      "id": "intermediate-cable",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "extended-attribute"
      },
      "source": [
        "We do not need the `Id` column."
      ],
      "id": "extended-attribute"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "marked-cancellation"
      },
      "source": [
        "numeric_columns.remove('Id')"
      ],
      "id": "marked-cancellation",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "returning-vertex"
      },
      "source": [
        "Now we extract the numeric data."
      ],
      "id": "returning-vertex"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "irish-probe",
        "outputId": "0567a2dd-3073-4729-8fc5-7c87c9c9ca3c"
      },
      "source": [
        "numeric_data = raw_data[numeric_columns]\n",
        "numeric_data.head()"
      ],
      "id": "irish-probe",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>196.0</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>162.0</td>\n",
              "      <td>486</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>350.0</td>\n",
              "      <td>655</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MSSubClass  LotFrontage  LotArea  ...  MoSold  YrSold  SalePrice\n",
              "0          60         65.0     8450  ...       2    2008     208500\n",
              "1          20         80.0     9600  ...       5    2007     181500\n",
              "2          60         68.0    11250  ...       9    2008     223500\n",
              "3          70         60.0     9550  ...       2    2006     140000\n",
              "4          60         84.0    14260  ...      12    2008     250000\n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "warming-cartoon"
      },
      "source": [
        "Now let's deal with the missing values in the data."
      ],
      "id": "warming-cartoon"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obvious-rider",
        "outputId": "4b7dda02-637e-4e73-dee9-09572a209d3d"
      },
      "source": [
        "nan_columns = np.any(pd.isna(numeric_data), axis = 0)\n",
        "nan_columns = list(nan_columns[nan_columns == True].index)\n",
        "nan_columns"
      ],
      "id": "obvious-rider",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "activated-center"
      },
      "source": [
        "We simply replace them with zero."
      ],
      "id": "activated-center"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quarterly-murray",
        "outputId": "39655514-9567-4a34-e141-581920a32955"
      },
      "source": [
        "numeric_data['LotFrontage'] = numeric_data['LotFrontage'].fillna(0)\n",
        "numeric_data['MasVnrArea'] = numeric_data['MasVnrArea'].fillna(0)\n",
        "numeric_data['GarageYrBlt'] = numeric_data['GarageYrBlt'].fillna(0)"
      ],
      "id": "quarterly-murray",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joined-grade"
      },
      "source": [
        "let's split the data for training and test!"
      ],
      "id": "joined-grade"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "northern-welsh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "numeric_data_train, numeric_data_test = train_test_split(numeric_data, test_size=0.1)"
      ],
      "id": "northern-welsh",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "automatic-candy"
      },
      "source": [
        "### Normalizing the data\n",
        "Before training our linear regression model, we have to normalize the data. We do this by subtracting each column from its minimum value and then dividing it by the difference between maximum and minimum."
      ],
      "id": "automatic-candy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dominant-thanksgiving"
      },
      "source": [
        "# saving max, min for each column\n",
        "maxs, mins = dict(), dict()"
      ],
      "id": "dominant-thanksgiving",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pursuant-class"
      },
      "source": [
        "for col in numeric_data:\n",
        "    maxs[col] = numeric_data_train[col].max()\n",
        "    mins[col] = numeric_data_train[col].min()"
      ],
      "id": "pursuant-class",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "resistant-bathroom"
      },
      "source": [
        "numeric_data_train = (numeric_data_train - numeric_data_train.min()) / (numeric_data_train.max() - numeric_data_train.min())"
      ],
      "id": "resistant-bathroom",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sensitive-notion"
      },
      "source": [
        "## Building a Linear Regression model"
      ],
      "id": "sensitive-notion"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "insured-reviewer"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "id": "insured-reviewer",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "perfect-promise"
      },
      "source": [
        "numeric_x_columns = list(numeric_data_train.columns)\n",
        "numeric_x_columns.remove(\"SalePrice\")\n",
        "X_train_df = numeric_data_train[numeric_x_columns]\n",
        "y_train_df = pd.DataFrame(numeric_data_train[\"SalePrice\"])"
      ],
      "id": "perfect-promise",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wanted-surge"
      },
      "source": [
        "Now we have to convert the data into torch tensors. A `torch.Tensor` is a multi-dimensional matrix containing elements of a single data type. It's very similar to arrays in `NumPy`."
      ],
      "id": "wanted-surge"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ranging-hudson"
      },
      "source": [
        "X_train = torch.tensor(X_train_df.values, dtype=torch.float)\n",
        "y_train = torch.tensor(y_train_df.values, dtype=torch.float)"
      ],
      "id": "ranging-hudson",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prescribed-reason",
        "outputId": "2246437d-82fb-4df3-f322-780081fd44d1"
      },
      "source": [
        "print(X_train.size(), y_train.size())"
      ],
      "id": "prescribed-reason",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1314, 36]) torch.Size([1314, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baking-jamaica"
      },
      "source": [
        "### Defining a model with pytorch\n",
        "A model is always defined as a class in pytorch. It should have a `__init__` function in which you define the layers of your network. It also should have a `forward` function (method) that basically defines the forward pass on the network.\n",
        "\n",
        "For the beggining, let's start with a single layer network."
      ],
      "id": "baking-jamaica"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "written-motel"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, D_in, H1, D_out):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.linear1 = nn.Linear(D_in, H1)\n",
        "        self.linear2 = nn.Linear(H1, D_out)\n",
        "        self.activation = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        y_pred = self.activation(self.linear1(x))\n",
        "        y_pred = self.linear2(y_pred)\n",
        "        return y_pred"
      ],
      "id": "written-motel",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sustainable-blade"
      },
      "source": [
        "D_in, D_out = X_train.shape[1], y_train.shape[1]"
      ],
      "id": "sustainable-blade",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "subjective-camcorder"
      },
      "source": [
        "# defining the first model: an instance of the class \"Net\"\n",
        "model1 = Net(D_in, 500, D_out)"
      ],
      "id": "subjective-camcorder",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sticky-flash"
      },
      "source": [
        "The next steps is to define the __loss criterion__ and the __optimizer__ for the network. That is, we have to define the loss function we want to optimize during training and also the optimization method we are going to use, e.g, SGD, etc."
      ],
      "id": "sticky-flash"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "permanent-fancy"
      },
      "source": [
        "# MSE loss\n",
        "criterion = nn.MSELoss(reduction='sum')\n",
        "# SGD optimizer for finding the weights of the network\n",
        "optimizer = torch.optim.SGD(model1.parameters(), lr=1e-4)"
      ],
      "id": "permanent-fancy",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "individual-gentleman"
      },
      "source": [
        "Now, we are ready to do the training. We can simply do this by a for loop over the number of iterations. The training has 3 main steps:\n",
        "- A forward pass to compute the prediction for the current data point (batch).\n",
        "- computing the loss for the current prediction.\n",
        "- A backward pass to compute the gradient of the loss with respect to the weight of the network.\n",
        "- Finaly, updating the weights of the network (`optimizer.step()`).\n",
        "\n",
        "Note that in each backward pass pytorch saves the gradient for all of the parameters. Therefore it is important to replace the old gradient values with zero in the beggining of each iteration, otherwise the gradients will be accumulated during the iterations!"
      ],
      "id": "individual-gentleman"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "earlier-maximum",
        "outputId": "58efc1f8-5f81-49f7-a4a9-da55df48e9f8"
      },
      "source": [
        "losses1 = []\n",
        "\n",
        "for t in range(500):\n",
        "    y_pred = model1(X_train)\n",
        "    \n",
        "    loss = criterion(y_pred, y_train)\n",
        "    print(t, loss.item())\n",
        "    losses1.append(loss.item())\n",
        "    \n",
        "    if torch.isnan(loss):\n",
        "        break\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "id": "earlier-maximum",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 146.5303955078125\n",
            "1 1363.1669921875\n",
            "2 11021.28515625\n",
            "3 5159.28369140625\n",
            "4 43.230140686035156\n",
            "5 32.782310485839844\n",
            "6 27.2390193939209\n",
            "7 24.230106353759766\n",
            "8 22.531064987182617\n",
            "9 21.50863265991211\n",
            "10 20.83716583251953\n",
            "11 20.348913192749023\n",
            "12 19.95720100402832\n",
            "13 19.616718292236328\n",
            "14 19.30510139465332\n",
            "15 19.01072883605957\n",
            "16 18.727643966674805\n",
            "17 18.4523868560791\n",
            "18 18.182209014892578\n",
            "19 17.916404724121094\n",
            "20 17.654808044433594\n",
            "21 17.397430419921875\n",
            "22 17.143587112426758\n",
            "23 16.892662048339844\n",
            "24 16.645299911499023\n",
            "25 16.400793075561523\n",
            "26 16.1595516204834\n",
            "27 15.920892715454102\n",
            "28 15.684690475463867\n",
            "29 15.450624465942383\n",
            "30 15.218213081359863\n",
            "31 14.98702621459961\n",
            "32 14.757043838500977\n",
            "33 14.528696060180664\n",
            "34 14.301889419555664\n",
            "35 14.076449394226074\n",
            "36 13.852360725402832\n",
            "37 13.629881858825684\n",
            "38 13.409223556518555\n",
            "39 13.19043254852295\n",
            "40 12.973780632019043\n",
            "41 12.75988483428955\n",
            "42 12.547818183898926\n",
            "43 12.336686134338379\n",
            "44 12.126058578491211\n",
            "45 11.916820526123047\n",
            "46 11.709786415100098\n",
            "47 11.503676414489746\n",
            "48 11.298288345336914\n",
            "49 11.095205307006836\n",
            "50 10.894661903381348\n",
            "51 10.69730281829834\n",
            "52 10.503213882446289\n",
            "53 10.311199188232422\n",
            "54 10.121475219726562\n",
            "55 9.935107231140137\n",
            "56 9.75153636932373\n",
            "57 9.571600914001465\n",
            "58 9.394968032836914\n",
            "59 9.221110343933105\n",
            "60 9.050790786743164\n",
            "61 8.884465217590332\n",
            "62 8.72269058227539\n",
            "63 8.565617561340332\n",
            "64 8.412569999694824\n",
            "65 8.26351547241211\n",
            "66 8.11826229095459\n",
            "67 7.977080345153809\n",
            "68 7.839931488037109\n",
            "69 7.706549644470215\n",
            "70 7.577460289001465\n",
            "71 7.452785491943359\n",
            "72 7.332376480102539\n",
            "73 7.216353416442871\n",
            "74 7.10420036315918\n",
            "75 6.996270656585693\n",
            "76 6.892346382141113\n",
            "77 6.792119026184082\n",
            "78 6.695521831512451\n",
            "79 6.602443695068359\n",
            "80 6.512779712677002\n",
            "81 6.426448345184326\n",
            "82 6.343388557434082\n",
            "83 6.263559818267822\n",
            "84 6.186929702758789\n",
            "85 6.113312721252441\n",
            "86 6.042761325836182\n",
            "87 5.975034713745117\n",
            "88 5.91003942489624\n",
            "89 5.847657680511475\n",
            "90 5.787891387939453\n",
            "91 5.730594635009766\n",
            "92 5.675624370574951\n",
            "93 5.622942924499512\n",
            "94 5.57239294052124\n",
            "95 5.524038314819336\n",
            "96 5.477734565734863\n",
            "97 5.433403491973877\n",
            "98 5.390816688537598\n",
            "99 5.349923133850098\n",
            "100 5.310758113861084\n",
            "101 5.273194789886475\n",
            "102 5.2371602058410645\n",
            "103 5.2026047706604\n",
            "104 5.169396877288818\n",
            "105 5.137566566467285\n",
            "106 5.106935977935791\n",
            "107 5.0775532722473145\n",
            "108 5.049284934997559\n",
            "109 5.022147178649902\n",
            "110 4.996057033538818\n",
            "111 4.970913887023926\n",
            "112 4.946713924407959\n",
            "113 4.923360824584961\n",
            "114 4.900824069976807\n",
            "115 4.879087924957275\n",
            "116 4.858083248138428\n",
            "117 4.837777614593506\n",
            "118 4.818135738372803\n",
            "119 4.79913330078125\n",
            "120 4.780760288238525\n",
            "121 4.762988090515137\n",
            "122 4.745761394500732\n",
            "123 4.729116439819336\n",
            "124 4.7129645347595215\n",
            "125 4.697291851043701\n",
            "126 4.682061195373535\n",
            "127 4.667265892028809\n",
            "128 4.652876853942871\n",
            "129 4.6388750076293945\n",
            "130 4.625256061553955\n",
            "131 4.611992835998535\n",
            "132 4.599038600921631\n",
            "133 4.586411476135254\n",
            "134 4.574055194854736\n",
            "135 4.56195068359375\n",
            "136 4.550067901611328\n",
            "137 4.538478374481201\n",
            "138 4.527154445648193\n",
            "139 4.516085624694824\n",
            "140 4.505246162414551\n",
            "141 4.494619369506836\n",
            "142 4.4841694831848145\n",
            "143 4.4739274978637695\n",
            "144 4.463869094848633\n",
            "145 4.453981399536133\n",
            "146 4.444278717041016\n",
            "147 4.434760570526123\n",
            "148 4.4254231452941895\n",
            "149 4.416245460510254\n",
            "150 4.407208442687988\n",
            "151 4.3983025550842285\n",
            "152 4.389540672302246\n",
            "153 4.380914688110352\n",
            "154 4.372426509857178\n",
            "155 4.364075660705566\n",
            "156 4.355855941772461\n",
            "157 4.347769737243652\n",
            "158 4.33979606628418\n",
            "159 4.331913948059082\n",
            "160 4.3241448402404785\n",
            "161 4.316477298736572\n",
            "162 4.3088908195495605\n",
            "163 4.301395893096924\n",
            "164 4.29398775100708\n",
            "165 4.286656856536865\n",
            "166 4.279416561126709\n",
            "167 4.272268295288086\n",
            "168 4.265194416046143\n",
            "169 4.258203029632568\n",
            "170 4.2512712478637695\n",
            "171 4.2444047927856445\n",
            "172 4.237619400024414\n",
            "173 4.230896949768066\n",
            "174 4.224222183227539\n",
            "175 4.217598915100098\n",
            "176 4.211024284362793\n",
            "177 4.204512596130371\n",
            "178 4.198066711425781\n",
            "179 4.1917033195495605\n",
            "180 4.18540096282959\n",
            "181 4.179160118103027\n",
            "182 4.172966003417969\n",
            "183 4.1668243408203125\n",
            "184 4.16074275970459\n",
            "185 4.154707908630371\n",
            "186 4.1486968994140625\n",
            "187 4.142746925354004\n",
            "188 4.1368727684021\n",
            "189 4.131050109863281\n",
            "190 4.125275611877441\n",
            "191 4.119547367095947\n",
            "192 4.113866329193115\n",
            "193 4.108229637145996\n",
            "194 4.102629661560059\n",
            "195 4.097067356109619\n",
            "196 4.091552734375\n",
            "197 4.086077690124512\n",
            "198 4.0806379318237305\n",
            "199 4.075242519378662\n",
            "200 4.06989049911499\n",
            "201 4.064565181732178\n",
            "202 4.059275150299072\n",
            "203 4.054014205932617\n",
            "204 4.048787593841553\n",
            "205 4.043604850769043\n",
            "206 4.0384650230407715\n",
            "207 4.033364295959473\n",
            "208 4.028295516967773\n",
            "209 4.023238658905029\n",
            "210 4.018216609954834\n",
            "211 4.013222694396973\n",
            "212 4.008255481719971\n",
            "213 4.0033135414123535\n",
            "214 3.9984090328216553\n",
            "215 3.9935364723205566\n",
            "216 3.9886868000030518\n",
            "217 3.9838507175445557\n",
            "218 3.9790406227111816\n",
            "219 3.974243402481079\n",
            "220 3.969480276107788\n",
            "221 3.9647419452667236\n",
            "222 3.960033416748047\n",
            "223 3.9553565979003906\n",
            "224 3.950711965560913\n",
            "225 3.94608736038208\n",
            "226 3.9414873123168945\n",
            "227 3.9369189739227295\n",
            "228 3.932379722595215\n",
            "229 3.927861452102661\n",
            "230 3.9233644008636475\n",
            "231 3.9188790321350098\n",
            "232 3.9144110679626465\n",
            "233 3.9099678993225098\n",
            "234 3.9055631160736084\n",
            "235 3.90120530128479\n",
            "236 3.896925687789917\n",
            "237 3.8926706314086914\n",
            "238 3.888428211212158\n",
            "239 3.884216070175171\n",
            "240 3.8800435066223145\n",
            "241 3.8758904933929443\n",
            "242 3.8717596530914307\n",
            "243 3.867650270462036\n",
            "244 3.8635592460632324\n",
            "245 3.859506368637085\n",
            "246 3.8554880619049072\n",
            "247 3.8514962196350098\n",
            "248 3.847522020339966\n",
            "249 3.8435704708099365\n",
            "250 3.8396360874176025\n",
            "251 3.8357186317443848\n",
            "252 3.831820011138916\n",
            "253 3.8279316425323486\n",
            "254 3.8240511417388916\n",
            "255 3.8201851844787598\n",
            "256 3.816333770751953\n",
            "257 3.8124823570251465\n",
            "258 3.808635711669922\n",
            "259 3.804795503616333\n",
            "260 3.8009800910949707\n",
            "261 3.797226905822754\n",
            "262 3.793485641479492\n",
            "263 3.78975248336792\n",
            "264 3.7860333919525146\n",
            "265 3.782329559326172\n",
            "266 3.7786459922790527\n",
            "267 3.774989366531372\n",
            "268 3.7713491916656494\n",
            "269 3.767718553543091\n",
            "270 3.764096260070801\n",
            "271 3.760488986968994\n",
            "272 3.7569007873535156\n",
            "273 3.7533302307128906\n",
            "274 3.749778985977173\n",
            "275 3.7462477684020996\n",
            "276 3.7427310943603516\n",
            "277 3.7392189502716064\n",
            "278 3.735718250274658\n",
            "279 3.732229471206665\n",
            "280 3.72873592376709\n",
            "281 3.7252557277679443\n",
            "282 3.721789836883545\n",
            "283 3.7183420658111572\n",
            "284 3.7149159908294678\n",
            "285 3.7115020751953125\n",
            "286 3.708106517791748\n",
            "287 3.7047338485717773\n",
            "288 3.7013771533966064\n",
            "289 3.698040008544922\n",
            "290 3.694719076156616\n",
            "291 3.6914148330688477\n",
            "292 3.6881306171417236\n",
            "293 3.684859037399292\n",
            "294 3.6815996170043945\n",
            "295 3.6783499717712402\n",
            "296 3.6751232147216797\n",
            "297 3.6719131469726562\n",
            "298 3.6687099933624268\n",
            "299 3.6655049324035645\n",
            "300 3.6623151302337646\n",
            "301 3.6591408252716064\n",
            "302 3.655977249145508\n",
            "303 3.65282940864563\n",
            "304 3.649707078933716\n",
            "305 3.6466047763824463\n",
            "306 3.6435155868530273\n",
            "307 3.6404342651367188\n",
            "308 3.6373648643493652\n",
            "309 3.6343116760253906\n",
            "310 3.631272554397583\n",
            "311 3.6282527446746826\n",
            "312 3.6252431869506836\n",
            "313 3.6222405433654785\n",
            "314 3.619243860244751\n",
            "315 3.616257905960083\n",
            "316 3.6132824420928955\n",
            "317 3.6103153228759766\n",
            "318 3.607362747192383\n",
            "319 3.6044251918792725\n",
            "320 3.601501941680908\n",
            "321 3.598595142364502\n",
            "322 3.5956997871398926\n",
            "323 3.5928149223327637\n",
            "324 3.5899484157562256\n",
            "325 3.5870914459228516\n",
            "326 3.5842480659484863\n",
            "327 3.5814151763916016\n",
            "328 3.5785958766937256\n",
            "329 3.575791358947754\n",
            "330 3.5729970932006836\n",
            "331 3.570211410522461\n",
            "332 3.5674352645874023\n",
            "333 3.564669609069824\n",
            "334 3.561910390853882\n",
            "335 3.55916428565979\n",
            "336 3.556422233581543\n",
            "337 3.5536882877349854\n",
            "338 3.55096173286438\n",
            "339 3.5482499599456787\n",
            "340 3.5455474853515625\n",
            "341 3.5428662300109863\n",
            "342 3.540191650390625\n",
            "343 3.537526845932007\n",
            "344 3.5348734855651855\n",
            "345 3.532233953475952\n",
            "346 3.529602527618408\n",
            "347 3.5269761085510254\n",
            "348 3.5243582725524902\n",
            "349 3.521749496459961\n",
            "350 3.5191497802734375\n",
            "351 3.51655650138855\n",
            "352 3.5139708518981934\n",
            "353 3.5113961696624756\n",
            "354 3.5088307857513428\n",
            "355 3.5062742233276367\n",
            "356 3.5037224292755127\n",
            "357 3.5011720657348633\n",
            "358 3.498634099960327\n",
            "359 3.4961047172546387\n",
            "360 3.4935786724090576\n",
            "361 3.4910621643066406\n",
            "362 3.488553047180176\n",
            "363 3.4860572814941406\n",
            "364 3.4835782051086426\n",
            "365 3.481112480163574\n",
            "366 3.478649616241455\n",
            "367 3.47619366645813\n",
            "368 3.473745107650757\n",
            "369 3.471308708190918\n",
            "370 3.4688796997070312\n",
            "371 3.4664621353149414\n",
            "372 3.4640486240386963\n",
            "373 3.461646556854248\n",
            "374 3.4592514038085938\n",
            "375 3.45686674118042\n",
            "376 3.4544899463653564\n",
            "377 3.4521281719207764\n",
            "378 3.4497785568237305\n",
            "379 3.4474401473999023\n",
            "380 3.4451050758361816\n",
            "381 3.442779064178467\n",
            "382 3.4404587745666504\n",
            "383 3.4381556510925293\n",
            "384 3.435861587524414\n",
            "385 3.4335813522338867\n",
            "386 3.431302070617676\n",
            "387 3.4290342330932617\n",
            "388 3.4267687797546387\n",
            "389 3.4245123863220215\n",
            "390 3.4222607612609863\n",
            "391 3.4200167655944824\n",
            "392 3.4177775382995605\n",
            "393 3.4155447483062744\n",
            "394 3.4133167266845703\n",
            "395 3.4110944271087646\n",
            "396 3.408878803253174\n",
            "397 3.4066684246063232\n",
            "398 3.404463291168213\n",
            "399 3.402264356613159\n",
            "400 3.400074005126953\n",
            "401 3.397887706756592\n",
            "402 3.395709991455078\n",
            "403 3.3935353755950928\n",
            "404 3.3913698196411133\n",
            "405 3.389202833175659\n",
            "406 3.3870432376861572\n",
            "407 3.3848867416381836\n",
            "408 3.3827404975891113\n",
            "409 3.380596876144409\n",
            "410 3.3784618377685547\n",
            "411 3.3763270378112793\n",
            "412 3.374197483062744\n",
            "413 3.372079372406006\n",
            "414 3.3699703216552734\n",
            "415 3.367866039276123\n",
            "416 3.365767478942871\n",
            "417 3.3636763095855713\n",
            "418 3.3615875244140625\n",
            "419 3.3595054149627686\n",
            "420 3.357426404953003\n",
            "421 3.3553566932678223\n",
            "422 3.353288173675537\n",
            "423 3.3512299060821533\n",
            "424 3.349175214767456\n",
            "425 3.3471288681030273\n",
            "426 3.345088005065918\n",
            "427 3.3430540561676025\n",
            "428 3.341026544570923\n",
            "429 3.3390064239501953\n",
            "430 3.3369903564453125\n",
            "431 3.334980010986328\n",
            "432 3.3329761028289795\n",
            "433 3.330976724624634\n",
            "434 3.3289871215820312\n",
            "435 3.3270013332366943\n",
            "436 3.325023651123047\n",
            "437 3.3230533599853516\n",
            "438 3.3210906982421875\n",
            "439 3.3191282749176025\n",
            "440 3.317173957824707\n",
            "441 3.3152236938476562\n",
            "442 3.3132803440093994\n",
            "443 3.3113410472869873\n",
            "444 3.3094048500061035\n",
            "445 3.3074724674224854\n",
            "446 3.3055450916290283\n",
            "447 3.303617238998413\n",
            "448 3.30169415473938\n",
            "449 3.299773693084717\n",
            "450 3.2978577613830566\n",
            "451 3.2959513664245605\n",
            "452 3.294046640396118\n",
            "453 3.292146921157837\n",
            "454 3.2902514934539795\n",
            "455 3.2883572578430176\n",
            "456 3.286466121673584\n",
            "457 3.284576654434204\n",
            "458 3.282691717147827\n",
            "459 3.280813694000244\n",
            "460 3.2789394855499268\n",
            "461 3.2770748138427734\n",
            "462 3.2752113342285156\n",
            "463 3.2733542919158936\n",
            "464 3.271501064300537\n",
            "465 3.2696526050567627\n",
            "466 3.267808675765991\n",
            "467 3.2659666538238525\n",
            "468 3.2641313076019287\n",
            "469 3.262295961380005\n",
            "470 3.2604639530181885\n",
            "471 3.2586371898651123\n",
            "472 3.2568182945251465\n",
            "473 3.255004644393921\n",
            "474 3.2531940937042236\n",
            "475 3.2513883113861084\n",
            "476 3.249586582183838\n",
            "477 3.247788190841675\n",
            "478 3.2459938526153564\n",
            "479 3.2442026138305664\n",
            "480 3.242415428161621\n",
            "481 3.2406325340270996\n",
            "482 3.2388525009155273\n",
            "483 3.237071990966797\n",
            "484 3.235297203063965\n",
            "485 3.233522415161133\n",
            "486 3.23175311088562\n",
            "487 3.2299842834472656\n",
            "488 3.2282204627990723\n",
            "489 3.2264554500579834\n",
            "490 3.2246923446655273\n",
            "491 3.222933530807495\n",
            "492 3.2211759090423584\n",
            "493 3.219423532485962\n",
            "494 3.2176685333251953\n",
            "495 3.2159202098846436\n",
            "496 3.2141687870025635\n",
            "497 3.2124242782592773\n",
            "498 3.2106809616088867\n",
            "499 3.2089412212371826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coordinated-mexican"
      },
      "source": [
        "Now let's try a new model with more neurons in the hidden layer."
      ],
      "id": "coordinated-mexican"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cathedral-exercise"
      },
      "source": [
        "model2 = Net(D_in, 1000, D_out)"
      ],
      "id": "cathedral-exercise",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exposed-league"
      },
      "source": [
        "# MSE loss\n",
        "criterion = nn.MSELoss(reduction='sum')\n",
        "# SGD optimizer for finding the weights of the network\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=1e-4)"
      ],
      "id": "exposed-league",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "operational-paper"
      },
      "source": [
        "losses2 = []\n",
        "\n",
        "for t in range(500):\n",
        "    y_pred = model2(X_train)\n",
        "    \n",
        "    loss = criterion(y_pred, y_train)\n",
        "    # print(t, loss.item())\n",
        "    losses2.append(loss.item())\n",
        "    \n",
        "    if torch.isnan(loss):\n",
        "        break\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "id": "operational-paper",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "extra-consortium",
        "outputId": "fdc64212-cf89-4e3a-b3a4-92a939619cbb"
      },
      "source": [
        "plt.plot(losses1, label=\"model1\")\n",
        "plt.plot(losses2, label=\"model2\")\n",
        "plt.ylim([0, 70])\n",
        "plt.legend()"
      ],
      "id": "extra-consortium",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcfe5b8ab90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "banned-honolulu"
      },
      "source": [
        "Let's compare the MSE loss on the test data"
      ],
      "id": "banned-honolulu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "norwegian-mayor",
        "outputId": "7f618af7-4975-4002-a8c4-b02c49315537"
      },
      "source": [
        "# we need to normalize the test data with the min and max value\n",
        "# from the training data\n",
        "for col in numeric_data_test.columns:\n",
        "    numeric_data_test[col] = (numeric_data_test[col] - mins[col]) / (maxs[col] - mins[col])"
      ],
      "id": "norwegian-mayor",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "parallel-following",
        "outputId": "ab5f174d-96ed-4f8d-fb3e-b6068e6dc4a6"
      },
      "source": [
        "y_test_df = pd.DataFrame(numeric_data_test[\"SalePrice\"])\n",
        "y_test = torch.tensor(y_test_df.values, dtype=torch.float)\n",
        "x_test_df = numeric_data_test[numeric_x_columns]\n",
        "x_test = torch.tensor(x_test_df.values, dtype=torch.float)\n",
        "# prediction for model 1\n",
        "model1_pred = model1(x_test)\n",
        "print(\"MSE loss for model1: \", criterion(model1_pred, y_test))\n",
        "# prediction for model 2\n",
        "model2_pred = model2(x_test)\n",
        "print(\"MSE loss for model2: \", criterion(model2_pred, y_test))\n"
      ],
      "id": "parallel-following",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE loss for model1:  tensor(0.2860, grad_fn=<MseLossBackward>)\n",
            "MSE loss for model2:  tensor(0.2904, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrong-corporation"
      },
      "source": [
        "## Now it is your turn!\n",
        "### Exercises\n",
        "\n",
        "1- Let's get back to model1. This time try to train it with a new optimizer. Try the Adam optimizer (which has shown to be faster than SGD for non-convex functions) and compare the trainig loss curve with SGD. Plot the training loss for the model trained with SGD and Adam optimizer.\n",
        "\n",
        "Note1: Use `torch.optim.Adam(model1.parameters(), lr=...)`\n",
        "\n",
        "Note2: If you are interested, check [this nice post](https://ruder.io/optimizing-gradient-descent/index.html) on differen gradient descent optimization algorithms.\n",
        "\n",
        "2- This time we want to build a new model with a new architecture. Specifically, we want to train a network with 3 hidden layers on the data. You can use the following code to build the architecture. Use the values 500, 1000, 200 for H1, H2, and H3 respectively. Train this new network on the same training data and compare it with the model1 we built above.\n",
        "\n",
        "```\n",
        "class Net_new(nn.Module):\n",
        "    def __init__(self, D_in, H1, H2, H3, D_out):\n",
        "        super(Net_new, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(D_in, H1)\n",
        "        self.linear2 = nn.Linear(H1, H2)\n",
        "        self.linear3 = nn.Linear(H2, H3)\n",
        "        self.linear4 = nn.Linear(H3, D_out)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = self.activation(self.linear1(x))\n",
        "        y_pred = self.activation(self.linear2(y_pred))\n",
        "        y_pred = self.activation(self.linear3(y_pred))\n",
        "        y_pred = self.linear4(y_pred)\n",
        "        return y_pred\n",
        "```"
      ],
      "id": "wrong-corporation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "respiratory-drink"
      },
      "source": [
        ""
      ],
      "id": "respiratory-drink",
      "execution_count": null,
      "outputs": []
    }
  ]
}